{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3686a0d-f5ba-46b1-921e-3ea1b0842d05",
   "metadata": {},
   "source": [
    "# Top Down Memo Brute Force Approach Time Complexity O(nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7504f35-6828-42d1-b647-9e7441cbbbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mice': ['mice'], 'eatmice': ['mice', 'eat'], 'catseatmice': ['mice', 'eat', 'cats']}\n",
      "['mice', 'eat', 'cats']\n",
      "['cats', 'eat', 'mice']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "class SplittingString:\n",
    "    def split_sentence(self, dic, sentence):\n",
    "\n",
    "        memo = {}\n",
    "        \n",
    "        def helper(dic, sentence):\n",
    "            # Base case is if no more sentences \n",
    "            if not sentence:\n",
    "                return []\n",
    "            \n",
    "            # Base case if found in memo for dynamic programming approach\n",
    "            if sentence in memo:\n",
    "                return memo[sentence]\n",
    "            \n",
    "            for word in dic:\n",
    "                if sentence.startswith(word):\n",
    "                    split_word_prefix = sentence[len(word):]\n",
    "                    returned_list = helper(dic, split_word_prefix)\n",
    "                    \n",
    "                    if returned_list is not None:\n",
    "                        memo[sentence] = returned_list +[word]\n",
    "                        return memo[sentence]\n",
    "            # Found no word that matches in the dic\n",
    "            return None\n",
    "        \n",
    "        result = helper(dic, sentence)\n",
    "        print(memo)\n",
    "        return result\n",
    "\n",
    "    def bfs_bottom_top_split_sentence(self, dic, sentence):\n",
    "\n",
    "        splits = {\"\":[]}\n",
    "        # Prefix of the sentence that we have not processed yet\n",
    "        prefix_to_process = collections.deque([\"\"])\n",
    "\n",
    "        while prefix_to_process:\n",
    "            prefix = prefix_to_process.popleft()\n",
    "            # As soon as the prefix_to_process matches the sentence \n",
    "            if prefix == sentence:\n",
    "                return splits[sentence]\n",
    "\n",
    "            for word in dic:\n",
    "                if sentence[len(prefix):].startswith(word):\n",
    "                    next_prefix = prefix + word \n",
    "                    # Only add the new prefix only if it is know\n",
    "                    if next_prefix not in splits:\n",
    "                        splits[next_prefix] = splits[prefix] + [word]\n",
    "                        prefix_to_process.append(next_prefix)\n",
    "        return None\n",
    "ss = SplittingString()\n",
    "print(ss.split_sentence([\"cat\", \"cats\", \"eat\", \"mice\"], \"catseatmice\"))\n",
    "print(ss.bfs_bottom_top_split_sentence([\"cat\", \"cats\", \"eat\", \"mice\"], \"catseatmice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2df80-c15e-4afd-b014-ff6ad7872f31",
   "metadata": {},
   "source": [
    "# Bottom Up DP Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3324e41-0af3-4e6f-93f9-786d4d653ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
